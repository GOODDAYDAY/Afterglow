# REQ-001 Implementation Plan: Afterglow Project Init & Core Player

## Context

Afterglow is a local-first English shadowing player. Core principle: **Python only does ASR processing → outputs JSON;
everything else is a pure frontend player.**

**Environment:** Node 22 + npm 11, Python 3.13, Windows 11.

---

## Architecture

```
Frontend (React + Vite)          Backend (Python + FastAPI)
┌──────────────────────┐         ┌──────────────────────┐
│  User selects video  │         │                      │
│  via <input file>    │         │  POST /api/transcribe │
│  → blob URL playback │────────→│  (receives file)     │
│                      │         │  → Faster-Whisper    │
│  Receives JSON       │←────────│  → returns JSON      │
│  → drives all        │         │                      │
│  playback logic      │         │  That's it.          │
└──────────────────────┘         └──────────────────────┘
```

**Key point:** Backend does NOT serve or stream video. Frontend loads video directly via file picker (blob URL). Backend
is purely an ASR processing service.

## Project Structure

```
Afterglow/
├── frontend/                    # React + Vite + TypeScript
│   ├── src/
│   │   ├── components/
│   │   │   ├── VideoPlayer.tsx       # HTML5 video with blob URL
│   │   │   ├── TranscriptPanel.tsx   # Sentence list with sync
│   │   │   ├── FileLoader.tsx        # File picker + transcribe trigger
│   │   │   └── SettingsPanel.tsx     # Feature toggle UI
│   │   ├── hooks/
│   │   │   └── useFeatureToggle.ts   # Toggle state + localStorage
│   │   ├── services/
│   │   │   └── api.ts               # Backend API calls (transcribe only)
│   │   ├── types/
│   │   │   └── index.ts             # Shared TypeScript types
│   │   ├── App.tsx
│   │   ├── App.css
│   │   └── main.tsx
│   ├── package.json
│   ├── tsconfig.json
│   └── vite.config.ts              # Proxy /api → backend:8000
├── backend/
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py                 # FastAPI app, minimal
│   │   ├── routers/
│   │   │   ├── __init__.py
│   │   │   └── transcribe.py       # ASR endpoint
│   │   └── services/
│   │       ├── __init__.py
│   │       └── whisper_service.py  # Faster-Whisper wrapper
│   └── requirements.txt
├── docs/requirements/
└── .gitignore
```

## Video Loading & Playback Flow

1. User clicks file picker → selects local video (mp4, mkv, webm, etc.)
2. Frontend creates `URL.createObjectURL(file)` → feeds to `<video src=...>`
3. Video plays entirely in the browser — no backend involvement
4. User clicks "Transcribe" → frontend sends the video **file** to backend via `POST /api/transcribe` (multipart upload)
5. Backend processes with Faster-Whisper → returns JSON with timestamped segments
6. Frontend receives JSON → renders transcript panel → drives playback sync

## Implementation Steps

### Step 1: Project scaffolding

- `npm create vite@latest frontend -- --template react-ts`
- Create `backend/` directory structure
- `backend/requirements.txt`: fastapi, uvicorn, faster-whisper, python-multipart
- Update `.gitignore`: node_modules, whisper model cache, frontend dist
- `vite.config.ts`: proxy `/api` → `http://localhost:8000`

### Step 2: Backend — ASR service (minimal)

- `main.py`: FastAPI app with CORS
- `routers/transcribe.py`:
    - `POST /api/transcribe` — accepts video file upload (multipart), runs ASR, returns JSON
    - Returns `{ segments: [{id, start, end, text}], language }` directly
- `services/whisper_service.py`:
    - Auto-download model to `~/.afterglow/models/`
    - Transcribe function returning timestamped segments
    - Model size: `base` by default

### Step 3: Frontend — TypeScript types & API service

- `types/index.ts`: Segment, TranscribeResponse, FeatureToggleConfig
- `services/api.ts`: `transcribeVideo(file: File)` function

### Step 4: Frontend — Core components

- `FileLoader.tsx`: File input (`accept="video/*"`) + "Transcribe" button + loading state
- `VideoPlayer.tsx`: `<video>` element with blob URL, exposes ref for time control
- `TranscriptPanel.tsx`: Scrollable sentence list, click-to-seek, current sentence highlight
- `App.tsx`: Layout — top: file loader, main area: video (left) + transcript (right)

### Step 5: Frontend — Playback synchronization

- `onTimeUpdate` listener: find current segment by comparing `video.currentTime` with segment boundaries
- Auto-scroll transcript to current sentence
- CSS highlight for active sentence

### Step 6: Feature Toggle framework

- `useFeatureToggle.ts`: hook with localStorage persistence
- `SettingsPanel.tsx`: Gear icon → drawer/modal with toggle switches
- Pre-defined toggle keys (all off by default):
  `singleLoop`, `smartGap`, `subtitleBlock`, `pronunciationScore`, `spacedRepetition`, `fillInBlank`, `aiAnalysis`

---

## Verification

1. `cd backend && pip install -r requirements.txt && uvicorn app.main:app --reload --port 8000`
2. `cd frontend && npm install && npm run dev`
3. Test:
    - Select a local video → it plays in the browser
    - Click "Transcribe" → loading indicator → transcript appears
    - Click sentence → video jumps to that time
    - During playback → current sentence highlights + auto-scrolls
    - Settings panel → toggles render and persist on reload
