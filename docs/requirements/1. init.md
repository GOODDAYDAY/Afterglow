# REQ-001: Afterglow — Project Init & Core Player

## Overview

**Afterglow** is a local-first English shadowing player.

Core principle: **Video stays local, index comes first** — use ASR (Automatic Speech Recognition) to generate
timestamped subtitle JSON, and the frontend player drives video playback control based on that JSON.

## Technical Decisions

| Layer          | Technology                | Notes                                                                   |
|----------------|---------------------------|-------------------------------------------------------------------------|
| Frontend       | React + Vite + TypeScript | SPA player                                                              |
| Backend        | Python + FastAPI          | ASR processing & API service                                            |
| ASR Engine     | Faster-Whisper (bundled)  | Local model, auto-downloads on first run, stored in user data directory |
| Data Storage   | JSON files                | Stores video metadata and timestamped subtitles                         |
| Video Playback | HTML5 Video API           | Native API, no extra dependencies                                       |

## Constraints

- No paid APIs — ASR model runs entirely locally
- Model files are not committed to GitHub (excluded via .gitignore)
- Architecture should consider future packaging as a desktop executable
- All playback features are designed as **toggleable Feature Toggles** — users can enable/disable as needed

## Phase 1 (REQ-001) Scope

### 1. Project Scaffolding

- Monorepo structure: `frontend/` + `backend/`
- Frontend: React + Vite + TypeScript initialization
- Backend: Python + FastAPI initialization
- Dev environment config (ESLint, Prettier, requirements.txt)
- .gitignore config (exclude model files, node_modules, etc.)

### 2. Local Video Loading

- File picker to select local video files
- Support common video formats (mp4, mkv, webm, avi)
- Read and display video metadata

### 3. ASR Speech Recognition

- Faster-Whisper integration
- Auto model download management (downloads to user data directory on first use)
- Video → timestamped sentence-level subtitle JSON
- API endpoint: upload video file → return transcription result

```json
// Subtitle data format
{
  "video_path": "/path/to/video.mp4",
  "language": "en",
  "segments": [
    {"id": 0, "start": 0.50, "end": 2.30, "text": "Hi there!"},
    {"id": 1, "start": 2.80, "end": 5.10, "text": "Welcome to this lesson."}
  ]
}
```

### 4. Core Player

- Video playback area + right-side transcript panel layout
- Transcript panel: display all sentences, highlight the currently playing one
- Click-to-seek: click a sentence → `video.currentTime = segment.start`
- Basic playback controls: play/pause, progress bar, volume

### 5. Feature Toggle Framework

- Settings panel UI
- Toggle switch component
- Config persistence (localStorage)
- Pre-defined toggle slots for future features:
    - Single sentence loop
    - Smart gap (pause between sentences)
    - Subtitle blocker
    - Pronunciation scoring
    - Spaced repetition
    - Fill-in-the-blank
    - AI sentence analysis

## Acceptance Criteria

- [ ] Project structure is complete; frontend and backend can start independently
- [ ] Can load and play a local video file via file picker
- [ ] ASR processes local video and generates timestamped subtitle JSON
- [ ] Transcript panel syncs with playback; current sentence is highlighted
- [ ] Clicking a transcript entry seeks to the corresponding timestamp
- [ ] Feature toggle panel works correctly; state persists across reloads
- [ ] Code is clean; TypeScript has zero type errors

## Future Phases (Out of Scope)

| Phase   | Content                                                                                      | Requirement Doc |
|---------|----------------------------------------------------------------------------------------------|-----------------|
| Phase 2 | Shadowing mode (single-sentence loop, smart gap, continuous play, hotkeys)                   | TBD             |
| Phase 3 | Subtitle blocker + UI enhancements (adjustable blocker bar, speed control, waveform)         | TBD             |
| Phase 4 | Advanced features (pronunciation scoring, spaced repetition, fill-in-the-blank, AI analysis) | TBD             |
| Phase 5 | Desktop packaging (executable)                                                               | TBD             |

---

## Original Ideas

<details>
<summary>Click to expand original brainstorm</summary>

- Use Faster-Whisper local model for speech recognition
- Frontend player controls sentence-level playback via `ontimeupdate`
- Smart gap: auto-pause after each sentence for T×1.2 seconds to allow shadowing
- Hotkeys: Enter to replay, Space to pause, Up/Down to adjust speed
- Real-time recording comparison: Web Audio API recording + waveform comparison
- Subtitle blocker: block the video's embedded subtitles
- No video download feature needed — read local files only
- Model files not uploaded to GitHub
- Future packaging as desktop executable
- All features are toggleable

</details>
